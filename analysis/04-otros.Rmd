---
title: "otros"
author: "Álvaro Ritoré"
date: "2023-07-05"
# output: html_document
---
#Random Forest

## Random Forest of all variables
```{r}
#Sets a seed value for the random number generator in R, ensuring that the same sequence of random numbers is generated each time the code is run, for reproducibility purposes
set.seed(123) 

#Create data partition: 70% training set and 30% test set
train_partition <- createDataPartition(final_dataset$death_30days, p = 0.9, list = FALSE)
train_data <- final_dataset[train_partition, ]
test_data <- final_dataset[-train_partition, ]

#Train the Random Forest model
model_all <- randomForest(death_30days ~ age + gender + hospital_stay_days + icu_stay_days + tbi_seq_1 + tbi_any_seq + anytrauma_seq_1 + anytrauma_any_seq + consecutive_vm_days + mv_consecutive_7days + mv_consecutive_14days + mv_consecutive_21days + total_vm_days + mv_total_7days + mv_total_14days + mv_total_21days + mv_96traq + prolonged_mec_vent + apsiii + apsiii_prob + sapsii + sapsii_prob + gcs_min + gcs_motor + gcs_verbal + gcs_eyes + gcs_unable + sofa + respiration + coagulation + liver + cardiovascular + cns + renal, data = train_data)

# Print model summary
## The "Mean of squared residuals" metric indicates the quality of the model fit. A lower value indicates a better fit
## The "% Var explained" (% of explained variance) represents the proportion of the total variance of the response variable explained by the model
print(model_all)

## Obtain importance of variables
## The "IncNodePurity" values represent the relative importance of the variables in the prediction. A higher value indicates greater importance
var_importance_all <- importance(model_all)
print(var_importance_all)
varImpPlot(model_all, main="Importance of the variables in the prediction", gap=2, cex.axis=0.8)

#Make predictions in test date using trained model 
predictions_all <- predict(model_all, newdata = test_data)

#Evaluate model performance
confusion_matrix_all <- table(predictions_all, test_data$death_30days)
print('Confusion matrix to evaluate model performance')
confusion_matrix
accuracy <- sum(diag(confusion_matrix_all)) / sum(confusion_matrix_all)
print('Precision value: performance for predicting outcome')
accuracy

```

## Random Forest of mortality at 30 days

```{r}
#Train the Random Forest model
model_tbi_and_pmv <- randomForest(death_30days ~ tbi_seq_1 + prolonged_mec_vent, data = train_data)

# Print model summary
print(model_tbi_and_pmv)

# Obtain importance of variables
var_importance_tbi_and_pmv <- importance(model_tbi_and_pmv)
print(var_importance_tbi_and_pmv)
varImpPlot(model_tbi_and_pmv, main="Importance of the variables in the prediction", gap=2, cex.axis=0.8)

#Make predictions in test date using trained model 
predictions_tbi_and_all <- predict(model_tbi_and_pmv, newdata = test_data)

#Evaluate model performance
confusion_matrix_tbi_and_pmv <- table(predictions_tbi_and_all, test_data$tbi_seq_1)
print('Confusion matrix to evaluate model performance')
confusion_matrix_tbi_and_pmv
accuracy_tbi_and_pmv <- sum(diag(confusion_matrix_tbi_and_pmv)) / sum(confusion_matrix_tbi_and_pmv)
print('Precision value: performance for predicting outcome')
accuracy_tbi_and_pmv
```


